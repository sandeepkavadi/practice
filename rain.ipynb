{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "02a089b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "3d587588",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = os.getcwd()\n",
    "parent = os.path.join(root, 'data', 'rain')\n",
    "filename = os.listdir(parent)[0]\n",
    "file_path = os.path.join(parent, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "e3671962",
   "metadata": {},
   "outputs": [],
   "source": [
    "## read file into a dataframe\n",
    "df_orig = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "5c7ed0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a copy of the original dataframe\n",
    "df = df_orig.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ef3ee0",
   "metadata": {},
   "source": [
    "### Plan of action to pre-process the data\n",
    "\n",
    "1. Target variable for this data set is the RainTomorrow variable\n",
    "2. There are complications here since the data is time series data, there could e strong autocorrelations in the data\n",
    "3. Also given that there are locations in the data set there could also be strong spatial correlations that we need to watch out for\n",
    "4. Want to test the data for auto-correlation using: Durbin Watson test or Ljung-Box tets\n",
    "    a. The Adj. Dickey-Fuller test (ADF) is used to check for stationarity in timeseries data\n",
    "    b. ACF & PACF plot are also a visual way to check for Auto-correlation\n",
    "5. Train test split. Given the data is imbalanced interms of the labels, sugegst to do a startified sampling bsed on label set\n",
    "6. Need to draw out the pre-processing pipeline:\n",
    "    a. Missing values ffill and bfill. \n",
    "        1. Try median imputation as well \n",
    "        2. Try 3-day moving average as imputation technique\n",
    "        3. Check the overall statistics using describe and check difference between all three\n",
    "    b. Add the derived variable: Temp range\n",
    "    c. Scale (Standardize/Normalize) the numerical variable\n",
    "    d. Check if any of the variables can be discretized\n",
    "7. Have a bunch of candidate models for the task\n",
    "8. Use cross validation for model selection and hyper-parameter tuning (Grid/Randomized search CV)\n",
    "9. Evaluate Generalization error\n",
    "10.Monitor the performance of the model\n",
    "11. Check if updated data is available on the Australian website to download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "8a7d9009",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Location</th>\n",
       "      <th>MinTemp</th>\n",
       "      <th>MaxTemp</th>\n",
       "      <th>Rainfall</th>\n",
       "      <th>Evaporation</th>\n",
       "      <th>Sunshine</th>\n",
       "      <th>WindGustDir</th>\n",
       "      <th>WindGustSpeed</th>\n",
       "      <th>WindDir9am</th>\n",
       "      <th>...</th>\n",
       "      <th>Humidity9am</th>\n",
       "      <th>Humidity3pm</th>\n",
       "      <th>Pressure9am</th>\n",
       "      <th>Pressure3pm</th>\n",
       "      <th>Cloud9am</th>\n",
       "      <th>Cloud3pm</th>\n",
       "      <th>Temp9am</th>\n",
       "      <th>Temp3pm</th>\n",
       "      <th>RainToday</th>\n",
       "      <th>RainTomorrow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008-12-01</td>\n",
       "      <td>Albury</td>\n",
       "      <td>13.4</td>\n",
       "      <td>22.9</td>\n",
       "      <td>0.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>W</td>\n",
       "      <td>44.0</td>\n",
       "      <td>W</td>\n",
       "      <td>...</td>\n",
       "      <td>71.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1007.7</td>\n",
       "      <td>1007.1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.9</td>\n",
       "      <td>21.8</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008-12-02</td>\n",
       "      <td>Albury</td>\n",
       "      <td>7.4</td>\n",
       "      <td>25.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WNW</td>\n",
       "      <td>44.0</td>\n",
       "      <td>NNW</td>\n",
       "      <td>...</td>\n",
       "      <td>44.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1010.6</td>\n",
       "      <td>1007.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.2</td>\n",
       "      <td>24.3</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008-12-03</td>\n",
       "      <td>Albury</td>\n",
       "      <td>12.9</td>\n",
       "      <td>25.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WSW</td>\n",
       "      <td>46.0</td>\n",
       "      <td>W</td>\n",
       "      <td>...</td>\n",
       "      <td>38.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1007.6</td>\n",
       "      <td>1008.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>23.2</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2008-12-04</td>\n",
       "      <td>Albury</td>\n",
       "      <td>9.2</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NE</td>\n",
       "      <td>24.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>...</td>\n",
       "      <td>45.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1017.6</td>\n",
       "      <td>1012.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.1</td>\n",
       "      <td>26.5</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2008-12-05</td>\n",
       "      <td>Albury</td>\n",
       "      <td>17.5</td>\n",
       "      <td>32.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>W</td>\n",
       "      <td>41.0</td>\n",
       "      <td>ENE</td>\n",
       "      <td>...</td>\n",
       "      <td>82.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1010.8</td>\n",
       "      <td>1006.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>29.7</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date Location  MinTemp  MaxTemp  Rainfall  Evaporation  Sunshine  \\\n",
       "0  2008-12-01   Albury     13.4     22.9       0.6          NaN       NaN   \n",
       "1  2008-12-02   Albury      7.4     25.1       0.0          NaN       NaN   \n",
       "2  2008-12-03   Albury     12.9     25.7       0.0          NaN       NaN   \n",
       "3  2008-12-04   Albury      9.2     28.0       0.0          NaN       NaN   \n",
       "4  2008-12-05   Albury     17.5     32.3       1.0          NaN       NaN   \n",
       "\n",
       "  WindGustDir  WindGustSpeed WindDir9am  ... Humidity9am  Humidity3pm  \\\n",
       "0           W           44.0          W  ...        71.0         22.0   \n",
       "1         WNW           44.0        NNW  ...        44.0         25.0   \n",
       "2         WSW           46.0          W  ...        38.0         30.0   \n",
       "3          NE           24.0         SE  ...        45.0         16.0   \n",
       "4           W           41.0        ENE  ...        82.0         33.0   \n",
       "\n",
       "   Pressure9am  Pressure3pm  Cloud9am  Cloud3pm  Temp9am  Temp3pm  RainToday  \\\n",
       "0       1007.7       1007.1       8.0       NaN     16.9     21.8         No   \n",
       "1       1010.6       1007.8       NaN       NaN     17.2     24.3         No   \n",
       "2       1007.6       1008.7       NaN       2.0     21.0     23.2         No   \n",
       "3       1017.6       1012.8       NaN       NaN     18.1     26.5         No   \n",
       "4       1010.8       1006.0       7.0       8.0     17.8     29.7         No   \n",
       "\n",
       "   RainTomorrow  \n",
       "0            No  \n",
       "1            No  \n",
       "2            No  \n",
       "3            No  \n",
       "4            No  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Getting a high level feel of the data set\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "1bfdded4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 145460 entries, 0 to 145459\n",
      "Data columns (total 23 columns):\n",
      " #   Column         Non-Null Count   Dtype  \n",
      "---  ------         --------------   -----  \n",
      " 0   Date           145460 non-null  object \n",
      " 1   Location       145460 non-null  object \n",
      " 2   MinTemp        143975 non-null  float64\n",
      " 3   MaxTemp        144199 non-null  float64\n",
      " 4   Rainfall       142199 non-null  float64\n",
      " 5   Evaporation    82670 non-null   float64\n",
      " 6   Sunshine       75625 non-null   float64\n",
      " 7   WindGustDir    135134 non-null  object \n",
      " 8   WindGustSpeed  135197 non-null  float64\n",
      " 9   WindDir9am     134894 non-null  object \n",
      " 10  WindDir3pm     141232 non-null  object \n",
      " 11  WindSpeed9am   143693 non-null  float64\n",
      " 12  WindSpeed3pm   142398 non-null  float64\n",
      " 13  Humidity9am    142806 non-null  float64\n",
      " 14  Humidity3pm    140953 non-null  float64\n",
      " 15  Pressure9am    130395 non-null  float64\n",
      " 16  Pressure3pm    130432 non-null  float64\n",
      " 17  Cloud9am       89572 non-null   float64\n",
      " 18  Cloud3pm       86102 non-null   float64\n",
      " 19  Temp9am        143693 non-null  float64\n",
      " 20  Temp3pm        141851 non-null  float64\n",
      " 21  RainToday      142199 non-null  object \n",
      " 22  RainTomorrow   142193 non-null  object \n",
      "dtypes: float64(16), object(7)\n",
      "memory usage: 25.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "0269ae22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>RainTomorrow</th>\n",
       "      <th>False</th>\n",
       "      <th>True</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RainToday</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>140787</td>\n",
       "      <td>1412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>1406</td>\n",
       "      <td>1855</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "RainTomorrow   False  True\n",
       "RainToday                 \n",
       "False         140787  1412\n",
       "True            1406  1855"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Start by conveting the Date column to datetime\n",
    "df.Date = pd.to_datetime(df.Date, format='%Y-%m-%d')\n",
    "\n",
    "## First step is check the target variable\n",
    "\n",
    "### We may have an opportunity to fill missing values in target based on the values in RainToday column\n",
    "pd.crosstab(df.RainToday.isna(), df.RainTomorrow.isna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "1b362526",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning up target variable\n",
    "\n",
    "### So start by dropping columns with both values missing\n",
    "df = df[~((df.RainTomorrow.isna())&(df.RainToday.isna()))]\n",
    "\n",
    "## Check if we can impute the Rain tomorrow columns with Rain Today from next day\n",
    "\n",
    "df['rainTom_prev_day'] = df.sort_values(by=['Location', 'Date']).groupby('Location')['RainTomorrow'].shift(1)\n",
    "df['rainTod_next_day'] = df.sort_values(by=['Location', 'Date']).groupby('Location')['RainToday'].shift(-1)\n",
    "\n",
    "# # quick check\n",
    "# df[(df.Date.dt.year>=2009) & (df.Date <= df.Date.min()+pd.Timedelta(value=1, unit='days'))]   # works since NaNs are populated at the first day of each locaion\n",
    "\n",
    "\n",
    "df['RainTomorrow'] = df['RainTomorrow'].combine_first(df['rainTod_next_day'])\n",
    "df['RainToday'] = df['RainToday'].combine_first(df['rainTom_prev_day'])\n",
    "\n",
    "# # Doesn't look like there is much opportunity here\n",
    "df[df.RainTomorrow.isna()|df.RainToday.isna()]\n",
    "\n",
    "## Dropping rows where values for target variable are missing\n",
    "df = df[df.RainTomorrow.notna()].drop(['rainTod_next_day', 'rainTom_prev_day'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "cb297f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Incomplete data.\n",
    "## A. Dropping data prior to a particular timeperiod due to data being incomplete\n",
    "df = df[df.Date.dt.year>=2009]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "e34ca645",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>miss_pct</th>\n",
       "      <th>data_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MinTemp</th>\n",
       "      <td>0.448937</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MaxTemp</th>\n",
       "      <td>0.227328</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rainfall</th>\n",
       "      <td>0.992951</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Evaporation</th>\n",
       "      <td>43.262371</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sunshine</th>\n",
       "      <td>48.252148</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WindGustDir</th>\n",
       "      <td>6.350171</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WindGustSpeed</th>\n",
       "      <td>6.307994</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WindDir9am</th>\n",
       "      <td>7.093633</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WindDir3pm</th>\n",
       "      <td>2.687188</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WindSpeed9am</th>\n",
       "      <td>0.943626</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WindSpeed3pm</th>\n",
       "      <td>1.868664</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Humidity9am</th>\n",
       "      <td>1.251734</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Humidity3pm</th>\n",
       "      <td>2.566375</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pressure9am</th>\n",
       "      <td>9.950960</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pressure3pm</th>\n",
       "      <td>9.928084</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cloud9am</th>\n",
       "      <td>38.103170</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cloud3pm</th>\n",
       "      <td>40.553022</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Temp9am</th>\n",
       "      <td>0.634088</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Temp3pm</th>\n",
       "      <td>1.939436</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RainToday</th>\n",
       "      <td>0.992951</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                miss_pct data_type\n",
       "MinTemp         0.448937   float64\n",
       "MaxTemp         0.227328   float64\n",
       "Rainfall        0.992951   float64\n",
       "Evaporation    43.262371   float64\n",
       "Sunshine       48.252148   float64\n",
       "WindGustDir     6.350171    object\n",
       "WindGustSpeed   6.307994   float64\n",
       "WindDir9am      7.093633    object\n",
       "WindDir3pm      2.687188    object\n",
       "WindSpeed9am    0.943626   float64\n",
       "WindSpeed3pm    1.868664   float64\n",
       "Humidity9am     1.251734   float64\n",
       "Humidity3pm     2.566375   float64\n",
       "Pressure9am     9.950960   float64\n",
       "Pressure3pm     9.928084   float64\n",
       "Cloud9am       38.103170   float64\n",
       "Cloud3pm       40.553022   float64\n",
       "Temp9am         0.634088   float64\n",
       "Temp3pm         1.939436   float64\n",
       "RainToday       0.992951    object"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Handling missing values\n",
    "## Check for the current % of missing values in the dataset\n",
    "def get_missing(df):\n",
    "    s = df.isna().sum(axis=0)*100/len(df)\n",
    "    s = s[s>0].to_frame(name='miss_pct')\n",
    "    s = s.join(df.dtypes.to_frame(name='data_type'), how='left')\n",
    "    # s = s.merge(df.dtypes.to_frame(),how='left', left_index=True, right_index=True)\n",
    "    return s\n",
    "\n",
    "#### Calculating % of missing values in each column\n",
    "get_missing(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "4681f915",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling missing values\n",
    "\n",
    "## A. Dropping columns with high % of missing values\n",
    "miss_cols = get_missing(df)\n",
    "#### dropping coumns where there are more than 20% of values missing\n",
    "miss_cols = miss_cols[miss_cols.miss_pct>20].index.values ## .values returs an nd-numpy array\n",
    "miss_cols\n",
    "df = df.drop(miss_cols, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "0e795cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## B. Dropping Locations with missing values (i.e. data not being captured)\n",
    "\n",
    "miss_loc = df.groupby('Location').count()\n",
    "miss_loc = (miss_loc == 0).any(axis=1)\n",
    "miss_loc = miss_loc[miss_loc==True].index.values\n",
    "\n",
    "#### Check count of data pointsfor these locations in the dataset\n",
    "df['Location'].value_counts()/len(df)  # Most locations are pretty uniformly distributed interm of count\n",
    "\n",
    "#### Based on the above looks like dropping these locations is not going to significantly impact the analysis\n",
    "#### Dropping the locations missing ceratain variables\n",
    "df = df[~df.Location.isin(miss_loc)]    # given that this is not an index based drop, instead of using the drop function we simply filter the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "4b3cb3c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rainfall</th>\n",
       "      <th>RainToday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Rainfall, RainToday]\n",
       "Index: []"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.Rainfall.notna()&df.RainToday.isna()][['Rainfall', 'RainToday']]\n",
    "# df.Rainfall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "eef9260a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputation of Missing values\n",
    "\n",
    "## Opportunity to impute Temp3PM with MaxTemp and vice-versa\n",
    "df['Temp3pm'] = df['Temp3pm'].combine_first(df['MaxTemp']) \n",
    "df['MaxTemp'] = df['MaxTemp'].combine_first(df['Temp3pm']) \n",
    "\n",
    "## Rainfall. If Raintoday = No, then rainfall is zero \n",
    "df['Rainfall'] = np.where(df.RainToday == 'No', 0.0, df.Rainfall)\n",
    "# df[df.Rainfall.notna()&df.RainToday.isna()][['Rainfall', 'RainToday']]\n",
    "\n",
    "## Method 1: Forward & backward filling\n",
    "# df2 = df.sort_values(by=['Location', 'Date']).groupby(by=['Location']).fillna(axis=0, method='ffill')\\\n",
    "#             .fillna(axis=0, method='bfill')\n",
    "# df = df2.join(df['Location'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "61907b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame.merge(right, how='inner', on=None, left_on=None, right_on=None, left_index=False\n",
    "#                , right_index=False, sort=False, suffixes=('_x', '_y'), copy=None, indicator=False, validate=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "7ff51e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Imputation if missing values for categorical variables\n",
    "\n",
    "cat_miss = get_missing(df)\n",
    "cat_miss = cat_miss[cat_miss.data_type=='object'].index.values.tolist()\n",
    "\n",
    "# ## Forward filling missing categorical variables\n",
    "\n",
    "df[cat_miss] = df[['Location', 'Date']+cat_miss].sort_values(by=['Location', 'Date'])\\\n",
    "        .groupby('Location').fillna(method='ffill', axis=0).fillna(method='bfill', axis=0)[cat_miss]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "343c49a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_missing(df)\n",
    "stats_orig = df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd72e30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "1cf79bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Imputation if missing values for numeric variables\n",
    "## Three possible options\n",
    "## Method 1: Imputation with ffill/bfill\n",
    "## Method 2: Imputation with simple mean/median\n",
    "## Method 3: Imputation with rolling mean/median (simple/exponential)\n",
    "\n",
    "num_miss = get_missing(df)\n",
    "num_miss = num_miss[num_miss.data_type!='object'].index.values.tolist()\n",
    "num_miss = list(set(num_miss)-set(['Rainfall']))   # rainfall will be handled separately. Set needs a list passed set('Rainfall') didn't work \n",
    "num_miss\n",
    "\n",
    "#### Method 1: Imputation with ffill/bfill\n",
    "# df[num_miss] = df[['Location', 'Date']+num_miss].sort_values(by=['Location', 'Date'])\\\n",
    "#         .groupby('Location').fillna(method='ffill', axis=0).fillna(method='bfill', axis=0)[num_miss]\n",
    "stats_1 = df.describe().T\n",
    "\n",
    "#### Method 2a: Imputation with simple mean\n",
    "# df[num_miss] = df[num_miss].combine_first(df.groupby('Location')[num_miss].transform('mean'))\n",
    "stats_2a = df.describe().T\n",
    "\n",
    "#### Method 2b: Imputation with simple median\n",
    "# df[num_miss] = df[num_miss].combine_first(df.groupby('Location')[num_miss].transform('median'))\n",
    "stats_2b = df.describe().T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "id": "de455619",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">Date</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>nunique</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Location</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Adelaide</th>\n",
       "      <td>2924</td>\n",
       "      <td>2009-01-01</td>\n",
       "      <td>2017-06-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Albury</th>\n",
       "      <td>2981</td>\n",
       "      <td>2009-01-01</td>\n",
       "      <td>2017-06-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AliceSprings</th>\n",
       "      <td>3000</td>\n",
       "      <td>2009-01-01</td>\n",
       "      <td>2017-06-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BadgerysCreek</th>\n",
       "      <td>2928</td>\n",
       "      <td>2009-01-01</td>\n",
       "      <td>2017-06-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ballarat</th>\n",
       "      <td>2997</td>\n",
       "      <td>2009-01-01</td>\n",
       "      <td>2017-06-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bendigo</th>\n",
       "      <td>3003</td>\n",
       "      <td>2009-01-01</td>\n",
       "      <td>2017-06-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Brisbane</th>\n",
       "      <td>2978</td>\n",
       "      <td>2009-01-01</td>\n",
       "      <td>2017-06-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cairns</th>\n",
       "      <td>2957</td>\n",
       "      <td>2009-01-01</td>\n",
       "      <td>2017-06-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Canberra</th>\n",
       "      <td>2991</td>\n",
       "      <td>2009-01-01</td>\n",
       "      <td>2017-06-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cobar</th>\n",
       "      <td>2988</td>\n",
       "      <td>2009-01-01</td>\n",
       "      <td>2017-06-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CoffsHarbour</th>\n",
       "      <td>2953</td>\n",
       "      <td>2009-01-01</td>\n",
       "      <td>2017-06-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dartmoor</th>\n",
       "      <td>2943</td>\n",
       "      <td>2009-03-05</td>\n",
       "      <td>2017-06-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Darwin</th>\n",
       "      <td>3008</td>\n",
       "      <td>2009-01-01</td>\n",
       "      <td>2017-06-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GoldCoast</th>\n",
       "      <td>2950</td>\n",
       "      <td>2009-01-01</td>\n",
       "      <td>2017-06-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hobart</th>\n",
       "      <td>3004</td>\n",
       "      <td>2009-01-01</td>\n",
       "      <td>2017-06-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Katherine</th>\n",
       "      <td>1559</td>\n",
       "      <td>2013-03-01</td>\n",
       "      <td>2017-06-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Launceston</th>\n",
       "      <td>2997</td>\n",
       "      <td>2009-01-01</td>\n",
       "      <td>2017-06-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Melbourne</th>\n",
       "      <td>2251</td>\n",
       "      <td>2009-01-01</td>\n",
       "      <td>2017-06-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MelbourneAirport</th>\n",
       "      <td>3009</td>\n",
       "      <td>2009-01-01</td>\n",
       "      <td>2017-06-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mildura</th>\n",
       "      <td>3007</td>\n",
       "      <td>2009-01-01</td>\n",
       "      <td>2017-06-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Moree</th>\n",
       "      <td>2854</td>\n",
       "      <td>2009-01-01</td>\n",
       "      <td>2017-06-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MountGambier</th>\n",
       "      <td>2999</td>\n",
       "      <td>2009-01-01</td>\n",
       "      <td>2017-06-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nhil</th>\n",
       "      <td>1569</td>\n",
       "      <td>2013-03-01</td>\n",
       "      <td>2017-06-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NorahHead</th>\n",
       "      <td>2929</td>\n",
       "      <td>2009-01-01</td>\n",
       "      <td>2017-06-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NorfolkIsland</th>\n",
       "      <td>2964</td>\n",
       "      <td>2009-01-01</td>\n",
       "      <td>2017-06-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nuriootpa</th>\n",
       "      <td>3002</td>\n",
       "      <td>2009-01-01</td>\n",
       "      <td>2017-06-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PearceRAAF</th>\n",
       "      <td>2762</td>\n",
       "      <td>2009-01-01</td>\n",
       "      <td>2017-06-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Perth</th>\n",
       "      <td>3009</td>\n",
       "      <td>2009-01-01</td>\n",
       "      <td>2017-06-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PerthAirport</th>\n",
       "      <td>3009</td>\n",
       "      <td>2009-01-01</td>\n",
       "      <td>2017-06-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Portland</th>\n",
       "      <td>2996</td>\n",
       "      <td>2009-01-01</td>\n",
       "      <td>2017-06-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Richmond</th>\n",
       "      <td>2951</td>\n",
       "      <td>2009-01-01</td>\n",
       "      <td>2017-06-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sale</th>\n",
       "      <td>3000</td>\n",
       "      <td>2009-01-01</td>\n",
       "      <td>2017-06-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sydney</th>\n",
       "      <td>3002</td>\n",
       "      <td>2009-01-01</td>\n",
       "      <td>2017-06-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SydneyAirport</th>\n",
       "      <td>3005</td>\n",
       "      <td>2009-01-01</td>\n",
       "      <td>2017-06-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Townsville</th>\n",
       "      <td>3002</td>\n",
       "      <td>2009-01-01</td>\n",
       "      <td>2017-06-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tuggeranong</th>\n",
       "      <td>2967</td>\n",
       "      <td>2009-01-01</td>\n",
       "      <td>2017-06-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Uluru</th>\n",
       "      <td>1521</td>\n",
       "      <td>2013-03-01</td>\n",
       "      <td>2017-06-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WaggaWagga</th>\n",
       "      <td>2976</td>\n",
       "      <td>2009-01-01</td>\n",
       "      <td>2017-06-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Walpole</th>\n",
       "      <td>2819</td>\n",
       "      <td>2009-01-01</td>\n",
       "      <td>2017-06-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Watsonia</th>\n",
       "      <td>2999</td>\n",
       "      <td>2009-01-01</td>\n",
       "      <td>2017-06-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Williamtown</th>\n",
       "      <td>2553</td>\n",
       "      <td>2009-01-01</td>\n",
       "      <td>2017-06-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Witchcliffe</th>\n",
       "      <td>2952</td>\n",
       "      <td>2009-01-01</td>\n",
       "      <td>2017-06-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wollongong</th>\n",
       "      <td>2954</td>\n",
       "      <td>2009-01-01</td>\n",
       "      <td>2017-06-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Woomera</th>\n",
       "      <td>2990</td>\n",
       "      <td>2009-01-01</td>\n",
       "      <td>2017-06-24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Date                      \n",
       "                 nunique        min        max\n",
       "Location                                      \n",
       "Adelaide            2924 2009-01-01 2017-06-24\n",
       "Albury              2981 2009-01-01 2017-06-25\n",
       "AliceSprings        3000 2009-01-01 2017-06-24\n",
       "BadgerysCreek       2928 2009-01-01 2017-06-25\n",
       "Ballarat            2997 2009-01-01 2017-06-25\n",
       "Bendigo             3003 2009-01-01 2017-06-25\n",
       "Brisbane            2978 2009-01-01 2017-06-25\n",
       "Cairns              2957 2009-01-01 2017-06-25\n",
       "Canberra            2991 2009-01-01 2017-06-25\n",
       "Cobar               2988 2009-01-01 2017-06-25\n",
       "CoffsHarbour        2953 2009-01-01 2017-06-25\n",
       "Dartmoor            2943 2009-03-05 2017-06-25\n",
       "Darwin              3008 2009-01-01 2017-06-24\n",
       "GoldCoast           2950 2009-01-01 2017-06-25\n",
       "Hobart              3004 2009-01-01 2017-06-25\n",
       "Katherine           1559 2013-03-01 2017-06-23\n",
       "Launceston          2997 2009-01-01 2017-06-25\n",
       "Melbourne           2251 2009-01-01 2017-06-25\n",
       "MelbourneAirport    3009 2009-01-01 2017-06-25\n",
       "Mildura             3007 2009-01-01 2017-06-25\n",
       "Moree               2854 2009-01-01 2017-06-25\n",
       "MountGambier        2999 2009-01-01 2017-06-24\n",
       "Nhil                1569 2013-03-01 2017-06-25\n",
       "NorahHead           2929 2009-01-01 2017-06-25\n",
       "NorfolkIsland       2964 2009-01-01 2017-06-25\n",
       "Nuriootpa           3002 2009-01-01 2017-06-24\n",
       "PearceRAAF          2762 2009-01-01 2017-06-25\n",
       "Perth               3009 2009-01-01 2017-06-25\n",
       "PerthAirport        3009 2009-01-01 2017-06-25\n",
       "Portland            2996 2009-01-01 2017-06-25\n",
       "Richmond            2951 2009-01-01 2017-06-25\n",
       "Sale                3000 2009-01-01 2017-06-25\n",
       "Sydney              3002 2009-01-01 2017-06-25\n",
       "SydneyAirport       3005 2009-01-01 2017-06-25\n",
       "Townsville          3002 2009-01-01 2017-06-25\n",
       "Tuggeranong         2967 2009-01-01 2017-06-25\n",
       "Uluru               1521 2013-03-01 2017-06-24\n",
       "WaggaWagga          2976 2009-01-01 2017-06-25\n",
       "Walpole             2819 2009-01-01 2017-06-25\n",
       "Watsonia            2999 2009-01-01 2017-06-25\n",
       "Williamtown         2553 2009-01-01 2017-06-25\n",
       "Witchcliffe         2952 2009-01-01 2017-06-25\n",
       "Wollongong          2954 2009-01-01 2017-06-25\n",
       "Woomera             2990 2009-01-01 2017-06-24"
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['Location']).agg({'Date':['nunique', 'min', 'max']})\n",
    "# import datetime as dt\n",
    "# dt.datetime.strptime('2009-01-01', '%Y-%m-%d') - dt.datetime.strptime('2017-06-24', '%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "id": "f939023a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Location</th>\n",
       "      <th>Date</th>\n",
       "      <th>gaps</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Location, Date, gaps]\n",
       "Index: []"
      ]
     },
     "execution_count": 461,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xyz = pd.date_range(start=df.Date.min(), end=df.Date.max(), freq='D').to_frame(name='Date')\n",
    "xyz['key'] = 0\n",
    "yzx = pd.DataFrame(df.loc[:,'Location'].unique(), columns=['Location'])\n",
    "yzx['key'] = 0\n",
    "xyz=xyz.merge(yzx, on='key', how='outer').drop('key', axis=1)\n",
    "xyz = df.merge(xyz, on=['Location', 'Date'], how='outer')\n",
    "\n",
    "xyz = xyz.groupby(['Location', 'Date'])['Date'].mean().diff().rename('gaps').reset_index()\n",
    "xyz[xyz.gaps > pd.Timedelta(value=1, unit='days')]\n",
    "\n",
    "# xyz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "id": "4b57ad9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Location</th>\n",
       "      <th>Date</th>\n",
       "      <th>gaps</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1367</th>\n",
       "      <td>Adelaide</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>32 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4310</th>\n",
       "      <td>Albury</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>32 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7305</th>\n",
       "      <td>AliceSprings</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>32 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10261</th>\n",
       "      <td>BadgerysCreek</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>32 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13226</th>\n",
       "      <td>Ballarat</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>32 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16230</th>\n",
       "      <td>Bendigo</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>32 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19221</th>\n",
       "      <td>Brisbane</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>32 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22210</th>\n",
       "      <td>Cairns</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>32 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25158</th>\n",
       "      <td>Canberra</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>32 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28153</th>\n",
       "      <td>Cobar</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>32 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31144</th>\n",
       "      <td>CoffsHarbour</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>32 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34037</th>\n",
       "      <td>Dartmoor</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>32 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37043</th>\n",
       "      <td>Darwin</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>32 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40048</th>\n",
       "      <td>GoldCoast</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>32 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43000</th>\n",
       "      <td>Hobart</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>32 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47564</th>\n",
       "      <td>Launceston</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>32 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50432</th>\n",
       "      <td>Melbourne</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>32 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50990</th>\n",
       "      <td>Melbourne</td>\n",
       "      <td>2016-04-30</td>\n",
       "      <td>481 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52812</th>\n",
       "      <td>MelbourneAirport</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>32 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55821</th>\n",
       "      <td>Mildura</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>32 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58816</th>\n",
       "      <td>Moree</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>32 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61682</th>\n",
       "      <td>MountGambier</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>32 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66208</th>\n",
       "      <td>NorahHead</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>32 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69178</th>\n",
       "      <td>NorfolkIsland</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>32 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72142</th>\n",
       "      <td>Nuriootpa</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>32 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75018</th>\n",
       "      <td>PearceRAAF</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>32 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77907</th>\n",
       "      <td>Perth</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>32 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80916</th>\n",
       "      <td>PerthAirport</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>32 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83919</th>\n",
       "      <td>Portland</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>32 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86881</th>\n",
       "      <td>Richmond</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>32 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89872</th>\n",
       "      <td>Sale</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>32 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92869</th>\n",
       "      <td>Sydney</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>32 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95874</th>\n",
       "      <td>SydneyAirport</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>32 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98878</th>\n",
       "      <td>Townsville</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>32 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101856</th>\n",
       "      <td>Tuggeranong</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>32 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106369</th>\n",
       "      <td>WaggaWagga</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>32 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109159</th>\n",
       "      <td>Walpole</td>\n",
       "      <td>2012-10-19</td>\n",
       "      <td>89 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109202</th>\n",
       "      <td>Walpole</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>32 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112163</th>\n",
       "      <td>Watsonia</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>32 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115003</th>\n",
       "      <td>Williamtown</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>32 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117691</th>\n",
       "      <td>Witchcliffe</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>32 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120633</th>\n",
       "      <td>Wollongong</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>32 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123615</th>\n",
       "      <td>Woomera</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>32 days</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Location       Date     gaps\n",
       "1367            Adelaide 2013-01-01  32 days\n",
       "4310              Albury 2013-01-01  32 days\n",
       "7305        AliceSprings 2013-01-01  32 days\n",
       "10261      BadgerysCreek 2013-01-01  32 days\n",
       "13226           Ballarat 2013-01-01  32 days\n",
       "16230            Bendigo 2013-01-01  32 days\n",
       "19221           Brisbane 2013-01-01  32 days\n",
       "22210             Cairns 2013-01-01  32 days\n",
       "25158           Canberra 2013-01-01  32 days\n",
       "28153              Cobar 2013-01-01  32 days\n",
       "31144       CoffsHarbour 2013-01-01  32 days\n",
       "34037           Dartmoor 2013-01-01  32 days\n",
       "37043             Darwin 2013-01-01  32 days\n",
       "40048          GoldCoast 2013-01-01  32 days\n",
       "43000             Hobart 2013-01-01  32 days\n",
       "47564         Launceston 2013-01-01  32 days\n",
       "50432          Melbourne 2013-01-01  32 days\n",
       "50990          Melbourne 2016-04-30 481 days\n",
       "52812   MelbourneAirport 2013-01-01  32 days\n",
       "55821            Mildura 2013-01-01  32 days\n",
       "58816              Moree 2013-01-01  32 days\n",
       "61682       MountGambier 2013-01-01  32 days\n",
       "66208          NorahHead 2013-01-01  32 days\n",
       "69178      NorfolkIsland 2013-01-01  32 days\n",
       "72142          Nuriootpa 2013-01-01  32 days\n",
       "75018         PearceRAAF 2013-01-01  32 days\n",
       "77907              Perth 2013-01-01  32 days\n",
       "80916       PerthAirport 2013-01-01  32 days\n",
       "83919           Portland 2013-01-01  32 days\n",
       "86881           Richmond 2013-01-01  32 days\n",
       "89872               Sale 2013-01-01  32 days\n",
       "92869             Sydney 2013-01-01  32 days\n",
       "95874      SydneyAirport 2013-01-01  32 days\n",
       "98878         Townsville 2013-01-01  32 days\n",
       "101856       Tuggeranong 2013-01-01  32 days\n",
       "106369        WaggaWagga 2013-01-01  32 days\n",
       "109159           Walpole 2012-10-19  89 days\n",
       "109202           Walpole 2013-01-01  32 days\n",
       "112163          Watsonia 2013-01-01  32 days\n",
       "115003       Williamtown 2013-01-01  32 days\n",
       "117691       Witchcliffe 2013-01-01  32 days\n",
       "120633        Wollongong 2013-01-01  32 days\n",
       "123615           Woomera 2013-01-01  32 days"
      ]
     },
     "execution_count": 429,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Check if time series has gaps. This I gotta fix at the beginning\n",
    "# df.groupby(['Location', 'Date'])['Date'].mean().diff().rename('gaps').reset_index().groupby('gaps').agg({'Location':'nunique'\n",
    "#                                                                                                          , 'Date':['min', 'max']})\n",
    "\n",
    "d = df.groupby(['Location', 'Date'])['Date'].mean().diff().rename('gaps').reset_index()\n",
    "miss_gt_32d_locs = d[d.gaps > pd.Timedelta(value=32, unit='days')].Location.unique()   # Directly drop these locations\n",
    "d[d.gaps > pd.Timedelta(value=31, unit='days')]#.Location.unique()\n",
    "\n",
    "\n",
    "\n",
    "# df.sort_values(by=['Location', 'date']).groupby(['Location'])[num_miss].rolling(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "26246cbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "      <th>count_1</th>\n",
       "      <th>mean_1</th>\n",
       "      <th>std_1</th>\n",
       "      <th>min_1</th>\n",
       "      <th>25%_1</th>\n",
       "      <th>50%_1</th>\n",
       "      <th>75%_1</th>\n",
       "      <th>max_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MinTemp</th>\n",
       "      <td>125212.0</td>\n",
       "      <td>12.388714</td>\n",
       "      <td>6.388666</td>\n",
       "      <td>-8.2</td>\n",
       "      <td>7.7</td>\n",
       "      <td>12.1</td>\n",
       "      <td>17.1</td>\n",
       "      <td>33.9</td>\n",
       "      <td>125212.0</td>\n",
       "      <td>12.388714</td>\n",
       "      <td>6.388666</td>\n",
       "      <td>-8.2</td>\n",
       "      <td>7.7</td>\n",
       "      <td>12.1</td>\n",
       "      <td>17.1</td>\n",
       "      <td>33.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MaxTemp</th>\n",
       "      <td>125212.0</td>\n",
       "      <td>23.493390</td>\n",
       "      <td>7.009699</td>\n",
       "      <td>2.6</td>\n",
       "      <td>18.0</td>\n",
       "      <td>22.9</td>\n",
       "      <td>28.5</td>\n",
       "      <td>48.1</td>\n",
       "      <td>125212.0</td>\n",
       "      <td>23.493390</td>\n",
       "      <td>7.009699</td>\n",
       "      <td>2.6</td>\n",
       "      <td>18.0</td>\n",
       "      <td>22.9</td>\n",
       "      <td>28.5</td>\n",
       "      <td>48.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rainfall</th>\n",
       "      <td>124026.0</td>\n",
       "      <td>2.291718</td>\n",
       "      <td>8.592871</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>124026.0</td>\n",
       "      <td>2.291718</td>\n",
       "      <td>8.592871</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>371.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WindGustSpeed</th>\n",
       "      <td>125212.0</td>\n",
       "      <td>40.097842</td>\n",
       "      <td>13.454369</td>\n",
       "      <td>6.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>125212.0</td>\n",
       "      <td>40.097842</td>\n",
       "      <td>13.454369</td>\n",
       "      <td>6.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>135.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WindSpeed9am</th>\n",
       "      <td>125212.0</td>\n",
       "      <td>14.318843</td>\n",
       "      <td>8.788574</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>125212.0</td>\n",
       "      <td>14.318843</td>\n",
       "      <td>8.788574</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>87.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WindSpeed3pm</th>\n",
       "      <td>125212.0</td>\n",
       "      <td>19.006405</td>\n",
       "      <td>8.665763</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>125212.0</td>\n",
       "      <td>19.006405</td>\n",
       "      <td>8.665763</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>87.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Humidity9am</th>\n",
       "      <td>125212.0</td>\n",
       "      <td>68.438808</td>\n",
       "      <td>19.290425</td>\n",
       "      <td>0.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>125212.0</td>\n",
       "      <td>68.438808</td>\n",
       "      <td>19.290425</td>\n",
       "      <td>0.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Humidity3pm</th>\n",
       "      <td>125212.0</td>\n",
       "      <td>50.893485</td>\n",
       "      <td>20.758560</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>125212.0</td>\n",
       "      <td>50.893485</td>\n",
       "      <td>20.758560</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pressure9am</th>\n",
       "      <td>125212.0</td>\n",
       "      <td>1017.637832</td>\n",
       "      <td>7.042950</td>\n",
       "      <td>980.5</td>\n",
       "      <td>1013.0</td>\n",
       "      <td>1017.6</td>\n",
       "      <td>1022.3</td>\n",
       "      <td>1041.0</td>\n",
       "      <td>125212.0</td>\n",
       "      <td>1017.637832</td>\n",
       "      <td>7.042950</td>\n",
       "      <td>980.5</td>\n",
       "      <td>1013.0</td>\n",
       "      <td>1017.6</td>\n",
       "      <td>1022.3</td>\n",
       "      <td>1041.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pressure3pm</th>\n",
       "      <td>125212.0</td>\n",
       "      <td>1015.259218</td>\n",
       "      <td>6.967964</td>\n",
       "      <td>977.1</td>\n",
       "      <td>1010.5</td>\n",
       "      <td>1015.1</td>\n",
       "      <td>1019.9</td>\n",
       "      <td>1039.6</td>\n",
       "      <td>125212.0</td>\n",
       "      <td>1015.259218</td>\n",
       "      <td>6.967964</td>\n",
       "      <td>977.1</td>\n",
       "      <td>1010.5</td>\n",
       "      <td>1015.1</td>\n",
       "      <td>1019.9</td>\n",
       "      <td>1039.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Temp9am</th>\n",
       "      <td>125212.0</td>\n",
       "      <td>17.187635</td>\n",
       "      <td>6.471688</td>\n",
       "      <td>-3.1</td>\n",
       "      <td>12.4</td>\n",
       "      <td>16.8</td>\n",
       "      <td>21.8</td>\n",
       "      <td>40.2</td>\n",
       "      <td>125212.0</td>\n",
       "      <td>17.187635</td>\n",
       "      <td>6.471688</td>\n",
       "      <td>-3.1</td>\n",
       "      <td>12.4</td>\n",
       "      <td>16.8</td>\n",
       "      <td>21.8</td>\n",
       "      <td>40.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Temp3pm</th>\n",
       "      <td>125212.0</td>\n",
       "      <td>22.002614</td>\n",
       "      <td>6.872469</td>\n",
       "      <td>1.7</td>\n",
       "      <td>16.8</td>\n",
       "      <td>21.4</td>\n",
       "      <td>26.7</td>\n",
       "      <td>46.7</td>\n",
       "      <td>125212.0</td>\n",
       "      <td>22.002614</td>\n",
       "      <td>6.872469</td>\n",
       "      <td>1.7</td>\n",
       "      <td>16.8</td>\n",
       "      <td>21.4</td>\n",
       "      <td>26.7</td>\n",
       "      <td>46.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  count         mean        std    min     25%     50%  \\\n",
       "MinTemp        125212.0    12.388714   6.388666   -8.2     7.7    12.1   \n",
       "MaxTemp        125212.0    23.493390   7.009699    2.6    18.0    22.9   \n",
       "Rainfall       124026.0     2.291718   8.592871    0.0     0.0     0.0   \n",
       "WindGustSpeed  125212.0    40.097842  13.454369    6.0    31.0    39.0   \n",
       "WindSpeed9am   125212.0    14.318843   8.788574    0.0     7.0    13.0   \n",
       "WindSpeed3pm   125212.0    19.006405   8.665763    0.0    13.0    19.0   \n",
       "Humidity9am    125212.0    68.438808  19.290425    0.0    57.0    69.0   \n",
       "Humidity3pm    125212.0    50.893485  20.758560    0.0    36.0    52.0   \n",
       "Pressure9am    125212.0  1017.637832   7.042950  980.5  1013.0  1017.6   \n",
       "Pressure3pm    125212.0  1015.259218   6.967964  977.1  1010.5  1015.1   \n",
       "Temp9am        125212.0    17.187635   6.471688   -3.1    12.4    16.8   \n",
       "Temp3pm        125212.0    22.002614   6.872469    1.7    16.8    21.4   \n",
       "\n",
       "                  75%     max   count_1       mean_1      std_1  min_1  \\\n",
       "MinTemp          17.1    33.9  125212.0    12.388714   6.388666   -8.2   \n",
       "MaxTemp          28.5    48.1  125212.0    23.493390   7.009699    2.6   \n",
       "Rainfall          0.0   371.0  124026.0     2.291718   8.592871    0.0   \n",
       "WindGustSpeed    48.0   135.0  125212.0    40.097842  13.454369    6.0   \n",
       "WindSpeed9am     20.0    87.0  125212.0    14.318843   8.788574    0.0   \n",
       "WindSpeed3pm     24.0    87.0  125212.0    19.006405   8.665763    0.0   \n",
       "Humidity9am      83.0   100.0  125212.0    68.438808  19.290425    0.0   \n",
       "Humidity3pm      65.0   100.0  125212.0    50.893485  20.758560    0.0   \n",
       "Pressure9am    1022.3  1041.0  125212.0  1017.637832   7.042950  980.5   \n",
       "Pressure3pm    1019.9  1039.6  125212.0  1015.259218   6.967964  977.1   \n",
       "Temp9am          21.8    40.2  125212.0    17.187635   6.471688   -3.1   \n",
       "Temp3pm          26.7    46.7  125212.0    22.002614   6.872469    1.7   \n",
       "\n",
       "                25%_1   50%_1   75%_1   max_1  \n",
       "MinTemp           7.7    12.1    17.1    33.9  \n",
       "MaxTemp          18.0    22.9    28.5    48.1  \n",
       "Rainfall          0.0     0.0     0.0   371.0  \n",
       "WindGustSpeed    31.0    39.0    48.0   135.0  \n",
       "WindSpeed9am      7.0    13.0    20.0    87.0  \n",
       "WindSpeed3pm     13.0    19.0    24.0    87.0  \n",
       "Humidity9am      57.0    69.0    83.0   100.0  \n",
       "Humidity3pm      36.0    52.0    65.0   100.0  \n",
       "Pressure9am    1013.0  1017.6  1022.3  1041.0  \n",
       "Pressure3pm    1010.5  1015.1  1019.9  1039.6  \n",
       "Temp9am          12.4    16.8    21.8    40.2  \n",
       "Temp3pm          16.8    21.4    26.7    46.7  "
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats_orig.join(stats_1, rsuffix='_1')\\\n",
    "    .join(stats_2a, rsuffix='_2a')\\\n",
    "    .join(stats_2b, rsuffix='_2b')\\\n",
    "    .join(stats_3a, rsuffix='_3a')\\\n",
    "    .join(stats_3b, rsuffix='_3b')\\\n",
    "    \n",
    "# stats_orig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aaa6fc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "c49b5e7d",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (Temp/ipykernel_17188/4161569932.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\sande\\AppData\\Local\\Temp/ipykernel_17188/4161569932.py\"\u001b[1;36m, line \u001b[1;32m3\u001b[0m\n\u001b[1;33m    df['3d_rolling_avg_Rainfall'] = df.sort_values(by=['Location', 'Date']).groupby(by=['Location'])[]\u001b[0m\n\u001b[1;37m                                                                                                     ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Adding additional columns to the dataset\n",
    "df['temp_day_range'] = df['MaxTemp']-df['MinTemp']\n",
    "df['3d_rolling_avg_Rainfall'] = df.sort_values(by=['Location', 'Date']).groupby(by=['Location'])[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72926b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25eb4771",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd56c362",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6cdb08e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a0c4c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a62e9e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8ac76b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5a3032",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa58166d",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.relplot(data=df[df.Date.dt.year==2010]\n",
    "            , x='Date', y='Rainfall'\n",
    "            , col='RainTomorrow'#, hue='Location'\n",
    "            , kind='line'\n",
    "            , height=6, aspect=1\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d31ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.pairplot(data=df.sample(1000)\n",
    "#              , diag_kind='kde'\n",
    "#              , hue='RainToday'\n",
    "#             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96fb73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# alternatively: housing_num = housing.select_dtypes(include=[np.number])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e505dad0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2b60e909",
   "metadata": {},
   "source": [
    "### Plan of action to pre-process the data\n",
    "\n",
    "1. Target variable for this data set is the RainTomorrow variable\n",
    "2. There are complications here since the data is time series data, there could e strong autocorrelations in the data\n",
    "3. Also given that there are locations in the data set there could also be strong spatial correlations that we need to watch out for\n",
    "4. Want to test the data for auto-correlation using: Durbin Watson test or Ljung-Box tets\n",
    "    a. The Adj. Dickey-Fuller test (ADF) is used to check for stationarity in timeseries data\n",
    "    b. ACF & PACF plot are also a visual way to check for Auto-correlation\n",
    "5. Train test split. Given the data is imbalanced interms of the labels, sugegst to do a startified sampling bsed on label set\n",
    "6. Need to draw out the pre-processing pipeline:\n",
    "    a. Missing values ffill and bfill. \n",
    "        1. Try median imputation as well \n",
    "        2. Try 3-day moving average as imputation technique\n",
    "        3. Check the overall statistics using describe and check difference between all three\n",
    "    b. Add the derived variable: Temp range\n",
    "    c. Scale (Standardize/Normalize) the numerical variable\n",
    "    d. Check if any of the variables can be discretized\n",
    "7. Have a bunch of candidate models for the task\n",
    "8. Use cross validation for model selection and hyper-parameter tuning (Grid/Randomized search CV)\n",
    "9. Evaluate Generalization error\n",
    "10.Monitor the performance of the model\n",
    "11. Check if updated data is available on the Australian website to download\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e5c9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn as sk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a87b0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
